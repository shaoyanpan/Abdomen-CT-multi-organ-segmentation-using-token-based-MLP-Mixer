{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546ab4a9",
   "metadata": {},
   "source": [
    "# Here are the library you need to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52f4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F_tor\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "from timm.models.layers import DropPath\n",
    "from natsort import natsorted\n",
    "from monai.losses import DiceLoss, DiceCELoss,GeneralizedDiceLoss,DiceFocalLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "# from CONVIT_function import *\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    RandAffined,\n",
    "    RandCropByLabelClassesd,\n",
    "    SpatialPadd,\n",
    "    RandAdjustContrastd,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.transforms import (CastToTyped,\n",
    "                              Compose, CropForegroundd, EnsureChannelFirstd, LoadImaged,\n",
    "                              NormalizeIntensity, RandCropByPosNegLabeld,\n",
    "                              RandFlipd, RandGaussianNoised,\n",
    "                              RandGaussianSmoothd, RandScaleIntensityd,\n",
    "                              RandZoomd, SpatialCrop, SpatialPadd, EnsureTyped)\n",
    "from monai.networks.nets import UNETR,VNet,DynUNet,SwinUNETR\n",
    "from MLP_mixer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fce2e3",
   "metadata": {},
   "source": [
    "# Build the data loader using the monai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae31b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the dataloader hyper-parameters, including the batch size for training and testing,\n",
    "#class number (how many organs + 1 background),\n",
    "# patch size (the actual input img size), image spacing, and color channel (usually 1 for medical images)\n",
    "# And GPU\n",
    "BATCH_SIZE_TRAIN = 2\n",
    "BATCH_SIZE_TEST = 1\n",
    "actual_batch = 400\n",
    "patch_num = 2\n",
    "class_num = 14\n",
    "img_size = (256,256,160)\n",
    "patch_size = (64,64,64)\n",
    "spacing = (1,1,1.5)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4638219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use monai to process the nii data. If you use other format, check monai so it can read the data.\n",
    "# load image using PILreader (read nii) -> add channel dimension to the image -> ensure orientation -> respacing all image to\n",
    "# a same spacing -> intensity normalization -> padding or crop the boundary to ensure all images have same size\n",
    "\n",
    "# Important notice 1: the Orientationd and Spacingd functions takes a lot of time. You can delete them in each transformation\n",
    "# module depends on your requirements.\n",
    "\n",
    "# Important notice 2:\n",
    "# For CT which is quantative imaging, you must use this for normalization:\n",
    "# ScaleIntensityRanged(\n",
    "#     keys=[\"image\"],\n",
    "#     a_min=-self.min,\n",
    "#     a_max=self.max,\n",
    "#     b_min=0.0,\n",
    "#     b_max=1.0,\n",
    "#     clip=True,\n",
    "# ),\n",
    "\n",
    "# For MRI which is not quantative imaging, you must use this for normalization:\n",
    "# ScaleIntensityRanged(\n",
    "# ScaleIntensityd(\n",
    "#     keys=[\"image\"],\n",
    "#     minv=0,\n",
    "#     maxv=1.0,\n",
    "# ),\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,imgs_path,mask_path,if_aug = False,if_train = True):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.if_aug = if_aug\n",
    "        self.if_train = if_train\n",
    "        self.max = 1650\n",
    "        self.min = -1024\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        file_list = natsorted(glob.glob(self.imgs_path + \"*\"), key=lambda y: y.lower())\n",
    "        mask_list = natsorted(glob.glob(mask_path + \"*\"), key=lambda y: y.lower())\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "        self.loader = LoadImaged(keys= ['image','label'],reader='nibabelreader')\n",
    "        for img_path in file_list:\n",
    "            class_name = img_path.split(\"/\")[-1]\n",
    "            self.data.append([img_path, class_name])\n",
    "        for img_path in mask_list:\n",
    "            class_name = img_path.split(\"/\")[-1]\n",
    "            self.label.append([img_path, class_name])\n",
    "        self.class_num = class_num\n",
    "        self.read_transforms = Compose(\n",
    "                [\n",
    "                    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")])\n",
    "        \n",
    "        self.train_transforms = Compose(\n",
    "                [\n",
    "                    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                    Spacingd(\n",
    "                        keys=[\"image\", \"label\"],\n",
    "                        pixdim=spacing,\n",
    "                        mode=(\"bilinear\", \"nearest\"),\n",
    "                    ),\n",
    "                    \n",
    "                    # Normalization: choose the correct one based on the important notice 2 in the top of this block\n",
    "#                     ScaleIntensityd(\n",
    "#                         keys=[\"image\"],\n",
    "#                         minv=0,\n",
    "#                         maxv=1.0,\n",
    "#                     ),\n",
    "                    ScaleIntensityRanged(\n",
    "                        keys=[\"image\"],\n",
    "                        a_min=-self.min,\n",
    "                        a_max=self.max,\n",
    "                        b_min=0.0,\n",
    "                        b_max=1.0,\n",
    "                        clip=True,\n",
    "                    ),\n",
    "                    ResizeWithPadOrCropd(keys=[\"image\", \"label\"],\n",
    "                                    spatial_size = img_size,\n",
    "                                    mode=\"constant\",\n",
    "                                    constant_values = 0,\n",
    "                                    method = \"end\"),\n",
    "                    RandCropByLabelClassesd(keys=[\"image\", \"label\"],\n",
    "                                            label_key=\"label\",\n",
    "                                            spatial_size = patch_size,\n",
    "                                            num_classes=class_num,\n",
    "                                            num_samples=patch_num),\n",
    "                    \n",
    "                    \n",
    "                    # Augmentations: choose whatever you need\n",
    "                    RandAffined(keys = [\"image\",\"label\"], prob=0.5,\n",
    "                        mode=(\"bilinear\", \"nearest\"),\n",
    "                        rotate_range = (0.2,0.2,0.2),\n",
    "                        scale_range=((-0.3,0.3), (-0.3,0.3), (-0.3,0.3)),\n",
    "                        padding_mode=\"border\"),\n",
    "                    RandAdjustContrastd(keys=[\"image\"], prob=0.3, gamma=(0.95, 1.05)),\n",
    "                    RandGaussianNoised(keys=[\"image\"], std=0.01, prob=0.3),\n",
    "                    RandGaussianSmoothd(\n",
    "                        keys=[\"image\"],\n",
    "                        sigma_x=(0.5, 1.5),\n",
    "                        sigma_y=(0.5, 1.5),\n",
    "                        sigma_z=(0.5, 1.5),\n",
    "                        prob=0.15,\n",
    "                    ),\n",
    "                    RandShiftIntensityd(\n",
    "                        keys=[\"image\"],\n",
    "                        offsets=0.10,\n",
    "                        prob=0.50,\n",
    "                    ),\n",
    "                    ToTensord(keys=[\"image\", \"label\"]),\n",
    "                ]\n",
    "            )\n",
    "        self.train_transforms_noaug = Compose(\n",
    "                [\n",
    "                    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                    Spacingd(\n",
    "                        keys=[\"image\", \"label\"],\n",
    "                        pixdim=spacing,\n",
    "                        mode=(\"bilinear\", \"nearest\"),\n",
    "                    ),\n",
    "                    # ScaleIntensityd(\n",
    "                    #     keys=[\"image\"],\n",
    "                    #     minv=0,\n",
    "                    #     maxv=1.0,\n",
    "                    # ),\n",
    "                    ScaleIntensityRanged(\n",
    "                        keys=[\"image\"],\n",
    "                        a_min=-self.min,\n",
    "                        a_max=self.max,\n",
    "                        b_min=0.0,\n",
    "                        b_max=1.0,\n",
    "                        clip=True,\n",
    "                    ),\n",
    "                    ResizeWithPadOrCropd(keys=[\"image\", \"label\"],\n",
    "                                    spatial_size = img_size,\n",
    "                                    mode=\"constant\",\n",
    "                                    constant_values = 0,\n",
    "                                    method = \"end\"),\n",
    "                    RandCropByLabelClassesd(keys=[\"image\", \"label\"],\n",
    "                                            label_key=\"label\",\n",
    "                                            spatial_size = patch_size,\n",
    "                                            num_classes=class_num,\n",
    "                                            num_samples=patch_num),\n",
    "                    ToTensord(keys=[\"image\", \"label\"]),\n",
    "                ]\n",
    "            )    \n",
    "        \n",
    "        self.val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=spacing,\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                # ScaleIntensityd(\n",
    "                #         keys=[\"image\"],\n",
    "                #         minv=0,\n",
    "                #         maxv=1.0,\n",
    "                #     ),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-self.min,\n",
    "                    a_max=self.max,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                ),\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "        self.val_transforms_ori = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                Spacingd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    pixdim=spacing,\n",
    "                    mode=(\"bilinear\", \"nearest\"),\n",
    "                ),\n",
    "                # ScaleIntensityd(\n",
    "                #         keys=[\"image\"],\n",
    "                #         minv=0,\n",
    "                #         maxv=1.0,\n",
    "                #     ),\n",
    "                ScaleIntensityRanged(\n",
    "                        keys=[\"image\"],\n",
    "                        a_min=-self.min,\n",
    "                        a_max=self.max,\n",
    "                        b_min=0.0,\n",
    "                        b_max=1.0,\n",
    "                        clip=True,\n",
    "                    ),\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx,):\n",
    "\n",
    "        # aa = time.time() \n",
    "        img_path, class_name = self.data[idx]\n",
    "        mask_path, class_name = self.label[idx]\n",
    "        cao = {\"image\":img_path,'label':mask_path}\n",
    "\n",
    "        if self.if_train is True:\n",
    "            if self.if_aug is True:    \n",
    "                affined_data_dict = self.train_transforms(cao)                    \n",
    "                img = np.zeros([patch_num, self.patch_size[0], self.patch_size[1], self.patch_size[2]])\n",
    "                label = np.zeros([patch_num, self.patch_size[0], self.patch_size[1], self.patch_size[2]])\n",
    "                for i,after_l in enumerate(affined_data_dict):\n",
    "                    img[i,:,:,:] = after_l['image']\n",
    "                    label[i,:,:,:] = after_l['label']\n",
    "    \n",
    "                img_tensor = torch.unsqueeze(torch.from_numpy(img.copy()), 1).to(torch.float)\n",
    "                label_tensor = torch.from_numpy(label.copy()).to(torch.int64)\n",
    "                label_tensor = F_tor.one_hot(label_tensor,\n",
    "                                    num_classes=self.class_num).permute(0,4,1,2,3).squeeze()\n",
    "                \n",
    "            elif self.if_aug is False:\n",
    "                affined_data_dict = self.train_transforms_noaug(cao)      \n",
    "                img_tensor = affined_data_dict['image'].to(torch.float)\n",
    "                label_tensor = affined_data_dict['label'].to(torch.int64)                \n",
    "                label_tensor = F_tor.one_hot(label_tensor,\n",
    "                                    num_classes=self.class_num).permute(0,4,1,2,3).squeeze()  \n",
    "        \n",
    "        else:              \n",
    "            datac_dict =  self.val_transforms(cao)\n",
    "            ori_datac_dict =  self.val_transforms_ori(cao)\n",
    "            label_tensor = (F_tor.one_hot(datac_dict['label'].to(torch.int64),\n",
    "                                num_classes=self.class_num).permute(0,4,1,2,3)).squeeze()\n",
    "\n",
    "            orilabel_tensor = (F_tor.one_hot(ori_datac_dict['label'].to(torch.int64),\n",
    "                                num_classes=self.class_num).permute(0,4,1,2,3)).squeeze()\n",
    "\n",
    "            \n",
    "            img_tensor = {'data':datac_dict['image'].to(torch.float),\n",
    "                            'ori_data':ori_datac_dict['image'].to(torch.float)}\n",
    "\n",
    "            label_tensor = {'data':label_tensor.to(torch.int32),\n",
    "                            'ori_data':orilabel_tensor.to(torch.int32)}\n",
    "\n",
    "        return img_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d856f87",
   "metadata": {},
   "source": [
    "# Build the Token_MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7364c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channels: color channel for the input, usually 1 for medical images\n",
    "# out_channels: number of the segmentation classes, # of organs + 1(background)\n",
    "# depth: depth of the network\n",
    "# feature_size: Token size, controling how dense of the information extracted by the token. Larger -> more information, but easier to overfit.\n",
    "# hidden_size: Layer size, similar to the convolutional channel in CNNs. Larger -> more information, but easier to overfit.\n",
    "# But notice, hidden_size = 512 means 64,128,256,512 since depth = 4.\n",
    "# mlp_dim: MLP layer size in the MLP_Mixer, controling how much you want to learn from the token. Larger -> more information, but easier to overfit.\n",
    "\n",
    "model =  MLP_MIXER(\n",
    "    in_channels=1,\n",
    "    out_channels=class_num,\n",
    "    depth = 4,\n",
    "    feature_size=512,\n",
    "    hidden_size=512,\n",
    "    mlp_dim=512,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2e051",
   "metadata": {},
   "source": [
    "# In case you want to use other famous segmentation networks. They are built from MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00eeb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ViTResNet(nn.Module):\n",
    "#     def __init__(self, batch_size, num_classes=class_num, dim = 1024, num_tokens = 128, mlp_dim = 2048, heads = 16, depth = 16, emb_dropout = 0, dropout= 0.2):\n",
    "#         super(ViTResNet, self).__init__()\n",
    "#         self.L = num_tokens\n",
    "#         self.cT = dim*1\n",
    "#         self.mlp_dim = self.cT*2\n",
    "        \n",
    "#         # self.model = nnFormer(crop_size=(14,128,128),\n",
    "#         #         embedding_dim=96,\n",
    "#         #         input_channels=1, \n",
    "#         #         num_classes=class_num, \n",
    "#         #         conv_op=nn.Conv3d, \n",
    "#         #         patch_size=[1,4,4],\n",
    "#         #         window_size=[[3,5,5],[3,5,5],[7,10,10],[3,5,5]],\n",
    "#         #         down_stride=[[1,4,4],[1,8,8],[2,16,16],[4,32,32]],\n",
    "#         #         depths=[2, 2, 2, 2],   \n",
    "#         #         num_heads=[6, 12, 24, 48],\n",
    "#         #         # patch_size=[2,4,4],\n",
    "#         #         # window_size=[4,4,8,4],\n",
    "#         #         deep_supervision=False)  \n",
    "# #         self.model = SwinUNETR(\n",
    "# #                 img_size = img_size,\n",
    "# #                 in_channels=1,\n",
    "# #                 out_channels = class_num,\n",
    "# #                 depths = (2, 2, 2, 2),\n",
    "# #                 num_heads= (3, 6, 12, 24),\n",
    "# #                 feature_size = 96,\n",
    "# #                 norm_name = \"instance\",\n",
    "# #                 drop_rate = 0.0,\n",
    "# #                 attn_drop_rate = 0.0,\n",
    "# #                 dropout_path_rate = 0.2,\n",
    "# #                 normalize = True,\n",
    "# #                 use_checkpoint = False,\n",
    "# #                 spatial_dims = 3,\n",
    "# #             ).to(device)        \n",
    "#         # self.model = DynUNet(\n",
    "#         #         spatial_dims=3,\n",
    "#         #         in_channels=1,\n",
    "#         #         out_channels=class_num,\n",
    "#         #         kernel_size=kernels,\n",
    "#         #         strides=strides,\n",
    "#         #         upsample_kernel_size=strides[1:],\n",
    "#         #         norm_name=\"instance\",\n",
    "#         #         deep_supervision=False,\n",
    "#         #         res_block = True\n",
    "#         #     ) \n",
    "        \n",
    "\n",
    "#         # self.model = VNet(\n",
    "#         #         spatial_dims=3,\n",
    "#         #         in_channels=1,\n",
    "#         #         out_channels=class_num,\n",
    "#         #         dropout_prob = 0\n",
    "#         #     ).to(device)\n",
    "\n",
    "#         # self.model = UNETR(\n",
    "#         #     in_channels=1,\n",
    "#         #     out_channels=class_num,\n",
    "#         #     img_size=(96, 96, 96),\n",
    "#         #     feature_size=16,\n",
    "#         #     hidden_size=768,\n",
    "#         #     mlp_dim=3072,\n",
    "#         #     num_heads=12,\n",
    "#         #     pos_embed='perceptron',\n",
    "#         #     norm_name='instance',\n",
    "#         #     conv_block=True,\n",
    "#         #     res_block=True,\n",
    "#         #     dropout_rate=0.0).to(device)\n",
    "#     def forward(self, img, mask = None):\n",
    "#         x_out = self.model(img)\n",
    "#         return x_out\n",
    "# model = ViTResNet(BATCH_SIZE_TRAIN).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e95b3",
   "metadata": {},
   "source": [
    "# Build the loss functions for optimization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8df2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion1 =DiceCELoss(include_background=True,\n",
    "                            to_onehot_y=False,\n",
    "                            softmax=True,\n",
    "                            squared_pred=False,\n",
    "                            smooth_nr=1e-5,\n",
    "                            smooth_dr=1e-5).to(device)\n",
    "eval_criterion = DiceMetric(include_background=False,\n",
    "                          reduction=\"mean\",\n",
    "                          get_not_nans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c334f2d3",
   "metadata": {},
   "source": [
    "# Build the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ecfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter number is 58652448\n",
      "Learning rate is 0.001\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('parameter number is '+str(pytorch_total_params))\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print('Learning rate is '+str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15bbb1",
   "metadata": {},
   "source": [
    "# Build the training function. Run the training function once = one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b82d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer,data_loader1, loss_history):\n",
    "    \n",
    "    #1: set the model to training mode\n",
    "    total_samples = len(data_loader1.dataset)\n",
    "    model.train()\n",
    "    loss_sum = 0  \n",
    "    dice_loss_sum = 0\n",
    "    count = 0\n",
    "    alpha = 0.4\n",
    "    total_time = 0\n",
    "    \n",
    "    #2: Loop the whole dataset, x1 (traindata) is the image batch \n",
    "    for i, (x1,y1)in enumerate(data_loader1):\n",
    "\n",
    "\n",
    "        traindata = x1.to(device)\n",
    "        traintarget = y1.to(device)\n",
    "        \n",
    "        #3: since they are patch-based form, reshape the images so the patch channel converge into the batch channel\n",
    "        traindata = traindata.view(-1,traindata.shape[2],traindata.shape[3],traindata.shape[4],traindata.shape[5])\n",
    "        traintarget = traintarget.view(-1,traintarget.shape[2],traintarget.shape[3],traintarget.shape[4],traintarget.shape[5])\n",
    "        \n",
    "        #4: Optimize the Token_MLP network\n",
    "        aa = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(traindata)\n",
    "            \n",
    "        loss1 = loss_criterion1(output, traintarget)\n",
    "        loss = loss1\n",
    "        loss.backward()\n",
    "        loss_sum += loss.detach().cpu().numpy()\n",
    "        count += 1\n",
    "        optimizer.step()\n",
    "        print('optimization time: '+ str(time.time()-aa))\n",
    "        total_time += time.time()-aa\n",
    "        if i % 1 == 0:\n",
    "            print('[' +  '{:5}'.format(i * BATCH_SIZE_TRAIN) + '/' + '{:5}'.format(total_samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader1)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "\n",
    "    loss_sum /= count\n",
    "    loss_history.append(loss_sum)\n",
    "    print(\"Total time per sample is: \"+str(total_time))\n",
    "    print('Averaged loss is: '+ str(loss_sum))\n",
    "    print('Averaged  Dice loss is: '+ str(dice_loss_sum/(i+1)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ce336",
   "metadata": {},
   "source": [
    "# Build the testing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf8538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the patch-based prediction. You need to decide two parameters.\n",
    "overlap = 0.5 # Overlap ratio between the prediction patches\n",
    "mode = 'gaussian'  # Overlap mode between the prediction patches\n",
    "inferer = SlidingWindowInferer(img_size, patch_num,overlap,mode =mode)\n",
    "\n",
    "def evaluate(model,epoch,path, data_loader, loss_history,acc_history):\n",
    "    \n",
    "    #1: set the model to eval mode\n",
    "    model.eval()\n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    prediction = []\n",
    "    true = []\n",
    "    img = []\n",
    "    loss_all = []\n",
    "    acc_all = []\n",
    "    with torch.no_grad():\n",
    "        thetime = 0\n",
    "        \n",
    "        #2: Loop the testing dataset\n",
    "        for i, (data, target) in enumerate(data_loader):\n",
    "            \n",
    "            \n",
    "            #3: The following code will automatically convert the network output into the segmentation map\n",
    "            aa = time.time()\n",
    "            testtarget = target['ori_data'].to(device)\n",
    "            testdata = data['data'].to(device)\n",
    "            reconstructed_output = inferer(testdata,model)\n",
    "            reconstructed_output = F_tor.interpolate(reconstructed_output,\n",
    "                                      size=target['ori_data'].shape[2:], mode='trilinear', align_corners=False)\n",
    "            output = F_tor.softmax(reconstructed_output,dim=1)\n",
    "            loss = loss_criterion1(reconstructed_output, testtarget)            \n",
    "            \n",
    "            output1 = output.argmax(1)\n",
    "            output1 = F_tor.one_hot(output1,\n",
    "                        num_classes=class_num).permute(0,4,1,2,3)\n",
    "            \n",
    "            #4: Evaluation\n",
    "            acc = eval_criterion(output1, testtarget)\n",
    "            print(acc.cpu().numpy())\n",
    "\n",
    "            loss_all.append(loss.cpu().numpy())\n",
    "            acc_all.append(acc.cpu().numpy())\n",
    "            thetime += time.time()-aa\n",
    "            print('optimization time: '+ str(time.time()-aa))            \n",
    "            \n",
    "            img.append(data['ori_data'].squeeze().cpu().numpy())\n",
    "            true.append(testtarget.squeeze().argmax(0).cpu().numpy())                                                             \n",
    "            prediction.append(output1.squeeze().argmax(0).cpu().numpy())\n",
    "            thetarget = testtarget.squeeze().argmax(0).cpu().numpy()\n",
    "            thepred = output1.squeeze().argmax(0).cpu().numpy()\n",
    "\n",
    "        loss_history.append(np.nanmean(loss_all))\n",
    "        acc_history.append(np.nanmean(acc_all))        \n",
    "      \n",
    "        #5: Save the predictions into mat files\n",
    "        if np.nanmean(acc_all)> best_acc:\n",
    "            data = {\"Losshistory\":loss_history,\"img\":img,\n",
    "                    \"true\":true, \"prediction\":prediction}\n",
    "            scipy.io.savemat(path+ 'validation_epoch'+str(epoch)+'.mat',data)\n",
    "        return np.nanmean(acc_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdce57",
   "metadata": {},
   "source": [
    "# Set the data folder for data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d93e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your data folder\n",
    "training_set1 = CustomDataset('./example_data/imagesTr/',\n",
    "                              './example_data/labelsTr/',\n",
    "                              if_aug = True,if_train = True)\n",
    "\n",
    "test_set = CustomDataset('./example_data/imagesTs/',\n",
    "                          './example_data/labelsTs/',\n",
    "                          if_aug = False,if_train = False)\n",
    "\n",
    "# Enter your data reader parameters\n",
    "params = {'batch_size': BATCH_SIZE_TRAIN,\n",
    "          'shuffle': True,\n",
    "          'pin_memory': True,\n",
    "          'drop_last': False}\n",
    "testparams = {'batch_size': BATCH_SIZE_TEST, \n",
    "          'shuffle': False,\n",
    "          'pin_memory': True,\n",
    "          'drop_last': False}\n",
    "\n",
    "train_loader1 = torch.utils.data.DataLoader(training_set1, **params)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, **testparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a1c2b",
   "metadata": {},
   "source": [
    "# Start the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a567765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\transforms\\utils.py:556: UserWarning: no available indices of class 9 to crop, set the crop ratio of this class to zero.\n",
      "  warnings.warn(f\"no available indices of class {i} to crop, set the crop ratio of this class to zero.\")\n",
      "C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\transforms\\utils.py:556: UserWarning: no available indices of class 10 to crop, set the crop ratio of this class to zero.\n",
      "  warnings.warn(f\"no available indices of class {i} to crop, set the crop ratio of this class to zero.\")\n",
      "C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\transforms\\utils.py:556: UserWarning: no available indices of class 11 to crop, set the crop ratio of this class to zero.\n",
      "  warnings.warn(f\"no available indices of class {i} to crop, set the crop ratio of this class to zero.\")\n",
      "C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\transforms\\utils.py:556: UserWarning: no available indices of class 12 to crop, set the crop ratio of this class to zero.\n",
      "  warnings.warn(f\"no available indices of class {i} to crop, set the crop ratio of this class to zero.\")\n",
      "C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\transforms\\utils.py:556: UserWarning: no available indices of class 13 to crop, set the crop ratio of this class to zero.\n",
      "  warnings.warn(f\"no available indices of class {i} to crop, set the crop ratio of this class to zero.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 16, 16, 16])\n",
      "torch.Size([2, 64, 32, 32, 32])\n",
      "torch.Size([2, 14, 64, 64, 64])\n",
      "optimization time: 5.861515045166016\n",
      "[    0/    1 (  0%)]  Loss: 3.7575\n",
      "Total time per sample is: 5.861515045166016\n",
      "Averaged loss is: 3.757516384124756\n",
      "Averaged  Dice loss is: 0.0\n",
      "Execution time:  7.20 seconds\n",
      "torch.Size([2, 128, 64, 64, 40])\n",
      "torch.Size([2, 64, 128, 128, 80])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/1108966507.py\", line 20, in <module>\n",
      "    theacc = evaluate(model,epoch,path, test_loader, test_loss_history, test_acc_history)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/2552549526.py\", line 30, in evaluate\n",
      "    reconstructed_output = inferer(testdata,model)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\inferer.py\", line 192, in __call__\n",
      "    return sliding_window_inference(  # type: ignore\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\utils.py\", line 176, in sliding_window_inference\n",
      "    seg_prob_out = predictor(window_data, *args, **kwargs)  # batched patch segmentation\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Research\\caocaocao\\MLP_mixer.py\", line 382, in forward\n",
      "    x_out11 =  self.up_block1(x_out22,x)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 211, in forward\n",
      "    out = self.conv_block(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 144, in forward\n",
      "    out = self.conv2(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 607, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 602, in _conv_forward\n",
      "    return F.conv3d(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/1108966507.py\", line 20, in <module>\n",
      "    theacc = evaluate(model,epoch,path, test_loader, test_loss_history, test_acc_history)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/2552549526.py\", line 30, in evaluate\n",
      "    reconstructed_output = inferer(testdata,model)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\inferer.py\", line 192, in __call__\n",
      "    return sliding_window_inference(  # type: ignore\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\utils.py\", line 176, in sliding_window_inference\n",
      "    seg_prob_out = predictor(window_data, *args, **kwargs)  # batched patch segmentation\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Research\\caocaocao\\MLP_mixer.py\", line 382, in forward\n",
      "    x_out11 =  self.up_block1(x_out22,x)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 211, in forward\n",
      "    out = self.conv_block(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 144, in forward\n",
      "    out = self.conv2(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 607, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 602, in _conv_forward\n",
      "    return F.conv3d(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/1108966507.py\", line 20, in <module>\n",
      "    theacc = evaluate(model,epoch,path, test_loader, test_loss_history, test_acc_history)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Local\\Temp/ipykernel_25528/2552549526.py\", line 30, in evaluate\n",
      "    reconstructed_output = inferer(testdata,model)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\inferer.py\", line 192, in __call__\n",
      "    return sliding_window_inference(  # type: ignore\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\inferers\\utils.py\", line 176, in sliding_window_inference\n",
      "    seg_prob_out = predictor(window_data, *args, **kwargs)  # batched patch segmentation\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Research\\caocaocao\\MLP_mixer.py\", line 382, in forward\n",
      "    x_out11 =  self.up_block1(x_out22,x)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 211, in forward\n",
      "    out = self.conv_block(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py\", line 144, in forward\n",
      "    out = self.conv2(out)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 607, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\pshaoya\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\conv.py\", line 602, in _conv_forward\n",
      "    return F.conv3d(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\pshaoya\\Anaconda3\\envs\\DL\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Enter your total number of epoch\n",
    "N_EPOCHS = 500\n",
    "\n",
    "# Enter the address you save the checkpoint and the prediction examples\n",
    "path =\"./output/example-1/\"\n",
    "PATH = path+'ViTRes1.pt' # Use your own path\n",
    "best_acc = 0\n",
    "if not os.path.exists(path):\n",
    "  os.makedirs(path) \n",
    "train_loss_history, test_loss_history,test_acc_history = [], [], []\n",
    "\n",
    "# Uncomment this when you resume the checkpoint\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "for epoch in range(0, N_EPOCHS):\n",
    "    print('Epoch:', epoch)\n",
    "    start_time = time.time()\n",
    "    train(model, optimizer, train_loader1, train_loss_history)\n",
    "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\n",
    "    if epoch % 10 == 0:\n",
    "        theacc = evaluate(model,epoch,path, test_loader, test_loss_history, test_acc_history)\n",
    "        if theacc > best_acc:\n",
    "            print('Save the latest best model')\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            best_acc = theacc\n",
    "print('Execution time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5dca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
